{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-28T16:18:08.325794Z","iopub.execute_input":"2023-04-28T16:18:08.326225Z","iopub.status.idle":"2023-04-28T16:18:18.096737Z","shell.execute_reply.started":"2023-04-28T16:18:08.326178Z","shell.execute_reply":"2023-04-28T16:18:18.095246Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Loading the MNIST Data\nIt has 60,000 images in Training set and 10,000 images in Test set","metadata":{}},{"cell_type":"code","source":"(X_train,y_train), (X_test,y_test) = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:18.099206Z","iopub.execute_input":"2023-04-28T16:18:18.100279Z","iopub.status.idle":"2023-04-28T16:18:18.584524Z","shell.execute_reply.started":"2023-04-28T16:18:18.100222Z","shell.execute_reply":"2023-04-28T16:18:18.583105Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Let's grap the shape of the images","metadata":{}},{"cell_type":"code","source":"print(\"X_train Original Shape: \",X_train.shape)\nprint(\"y_train Original Shape: \",y_train.shape)\nprint(\"X_test Original Shape: \",X_test.shape)\nprint(\"y_test Original Shape: \",y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:18.586422Z","iopub.execute_input":"2023-04-28T16:18:18.586889Z","iopub.status.idle":"2023-04-28T16:18:18.594188Z","shell.execute_reply.started":"2023-04-28T16:18:18.586840Z","shell.execute_reply":"2023-04-28T16:18:18.592987Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"X_train Original Shape:  (60000, 28, 28)\ny_train Original Shape:  (60000,)\nX_test Original Shape:  (10000, 28, 28)\ny_test Original Shape:  (10000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Hence we can it is 28 x 28 images","metadata":{}},{"cell_type":"markdown","source":"### Time to see the first image of our dataset","metadata":{}},{"cell_type":"code","source":"index = 0\nplt.imshow(X_train[index],cmap='gray')\nplt.title(f\"The Digit is : {y_train[index]}\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:18.597768Z","iopub.execute_input":"2023-04-28T16:18:18.598461Z","iopub.status.idle":"2023-04-28T16:18:19.049926Z","shell.execute_reply.started":"2023-04-28T16:18:18.598376Z","shell.execute_reply":"2023-04-28T16:18:19.048685Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Keras is using the `Tensorflow` under the hood. And it follows the following syntax for `Feature train` and `Feature Test`\n(Batch, height, width, Channel)\n- Batch : It means how many Images to consider\n- Height: Height of the Images\n- Width : Width of the Images\n- Channel : 3 or 1 (RGB, GRAY) respectively\n","metadata":{}},{"cell_type":"code","source":"feature_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nfeature_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n\n# Will convert the data type to float of 32-bit\nfeature_train = feature_train.astype('float32')\nfeature_test = feature_test.astype('float32')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:19.051166Z","iopub.execute_input":"2023-04-28T16:18:19.051531Z","iopub.status.idle":"2023-04-28T16:18:19.147171Z","shell.execute_reply.started":"2023-04-28T16:18:19.051497Z","shell.execute_reply":"2023-04-28T16:18:19.145641Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Min-Max Scaling on Images\nWe do not have to apply any complex formula here, as we know the range of color is from 0 - 255 hence dividing it from 255 itself will reduce the range of matrix into 0 - 1","metadata":{}},{"cell_type":"code","source":"feature_train /= 255\nfeature_test /= 255","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:19.149197Z","iopub.execute_input":"2023-04-28T16:18:19.149632Z","iopub.status.idle":"2023-04-28T16:18:19.174696Z","shell.execute_reply.started":"2023-04-28T16:18:19.149594Z","shell.execute_reply":"2023-04-28T16:18:19.173513Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### One Hot Encoding\nWe have 10 Features hence to convert them into categorical values we will use one hot encoding. For example 2 will be displayed as [0,0,1,0,0,0,0,0,0,0,0]","metadata":{}},{"cell_type":"code","source":"target_train = np_utils.to_categorical(y_train,10)\ntarget_test = np_utils.to_categorical(y_test,10)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:18:19.176504Z","iopub.execute_input":"2023-04-28T16:18:19.176859Z","iopub.status.idle":"2023-04-28T16:18:19.183280Z","shell.execute_reply.started":"2023-04-28T16:18:19.176826Z","shell.execute_reply":"2023-04-28T16:18:19.181913Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Let's build the Convulational Neural Network Model","metadata":{}},{"cell_type":"markdown","source":"For the Concept of BatchNormalization : https://www.youtube.com/watch?v=yXOMHOpbon8\n- The Process of Batch normalization involves `Standardizing` the input values first. \n- Standardization is the process of setting up values of the dataset such that `mean = 0` and `STD = 1`\n- Then it is multiplied by some value and then added with another value.\n- This two variables are not tunable and it is completely on the network, what values it computes.\n- Now this output is `feed` as input of another layer.\n- BatchNormalization is applied `between every layer`. It also helps reducing `Overfitting` and does a bit of `Regularization` task.\n- It also solves problem like `vanishing gradient`, `unstable gradients problem`.\n- Also it is important to note that Batchnomalization makes the model training `Faster`.","metadata":{}},{"cell_type":"code","source":"# Initializing the model\nmodel = Sequential()\n\n# Adding the layer of convulation operation\nmodel.add(Conv2D(32, (3,3), input_shape=(28,28,1)))\n\n#Add the layer of Activation function\nmodel.add(Activation('relu'))\n\n#Add BatchNormalization\nmodel.add(BatchNormalization())\n\n#Again Convulation\nmodel.add(Conv2D(32,(3,3)))\n\n#Add the layer of Activation function\nmodel.add(Activation('relu'))\n\n#Add the max pooling\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#Add BatchNormalization\nmodel.add(BatchNormalization())\n\n#Again Convulation\nmodel.add(Conv2D(64,(3,3)))\n\n#Add the layer of Activation function\nmodel.add(Activation('relu'))\n\n#Add BatchNormalization\nmodel.add(BatchNormalization())\n\n#Again Convulation\nmodel.add(Conv2D(64,(3,3)))\n\n#Add the layer of Activation function\nmodel.add(Activation('relu'))\n\n#Add the max pooling\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n#Flatten\nmodel.add(Flatten())\n\n#Add BatchNormalization\nmodel.add(BatchNormalization())\n\n#Dense\nmodel.add(Dense(512))\n\n#Add the layer of Activation function\nmodel.add(Activation('relu'))\n\n#Add BatchNormalization\nmodel.add(BatchNormalization())\n\n#Regularisation to avoid Overfitting\nmodel.add(Dropout(0.3))\n\n#Dense\n#SoftMax function is used as we are dealing wiht categorical valriable\nmodel.add(Dense(10, activation='softmax'))\n\n#Summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:19:38.078315Z","iopub.execute_input":"2023-04-28T16:19:38.078772Z","iopub.status.idle":"2023-04-28T16:19:38.374738Z","shell.execute_reply.started":"2023-04-28T16:19:38.078734Z","shell.execute_reply":"2023-04-28T16:19:38.373483Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n                                                                 \n activation_2 (Activation)   (None, 26, 26, 32)        0         \n                                                                 \n batch_normalization_2 (Batc  (None, 26, 26, 32)       128       \n hNormalization)                                                 \n                                                                 \n conv2d_3 (Conv2D)           (None, 24, 24, 32)        9248      \n                                                                 \n activation_3 (Activation)   (None, 24, 24, 32)        0         \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n )                                                               \n                                                                 \n batch_normalization_3 (Batc  (None, 12, 12, 32)       128       \n hNormalization)                                                 \n                                                                 \n conv2d_4 (Conv2D)           (None, 10, 10, 64)        18496     \n                                                                 \n activation_4 (Activation)   (None, 10, 10, 64)        0         \n                                                                 \n batch_normalization_4 (Batc  (None, 10, 10, 64)       256       \n hNormalization)                                                 \n                                                                 \n conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n                                                                 \n activation_5 (Activation)   (None, 8, 8, 64)          0         \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1024)              0         \n                                                                 \n batch_normalization_5 (Batc  (None, 1024)             4096      \n hNormalization)                                                 \n                                                                 \n dense (Dense)               (None, 512)               524800    \n                                                                 \n activation_6 (Activation)   (None, 512)               0         \n                                                                 \n batch_normalization_6 (Batc  (None, 512)              2048      \n hNormalization)                                                 \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 10)                5130      \n                                                                 \n=================================================================\nTotal params: 601,578\nTrainable params: 598,250\nNon-trainable params: 3,328\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Now we will fit our data into Network","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(feature_train, target_train, batch_size=128, epochs=5, validation_data=(feature_test,target_test), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:32:38.738055Z","iopub.execute_input":"2023-04-28T16:32:38.738575Z","iopub.status.idle":"2023-04-28T16:39:37.362683Z","shell.execute_reply.started":"2023-04-28T16:32:38.738517Z","shell.execute_reply":"2023-04-28T16:39:37.360765Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/5\n469/469 [==============================] - 87s 178ms/step - loss: 0.1028 - accuracy: 0.9693 - val_loss: 0.4277 - val_accuracy: 0.8600\nEpoch 2/5\n469/469 [==============================] - 82s 174ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.0320 - val_accuracy: 0.9901\nEpoch 3/5\n469/469 [==============================] - 81s 173ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0384 - val_accuracy: 0.9882\nEpoch 4/5\n469/469 [==============================] - 83s 177ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0338 - val_accuracy: 0.9886\nEpoch 5/5\n469/469 [==============================] - 86s 182ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0243 - val_accuracy: 0.9938\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x753c818f4ed0>"},"metadata":{}}]},{"cell_type":"code","source":"score = model.evaluate(feature_test, target_test)\nprint(\"Test Accuracy: \",score[1])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T16:39:43.467739Z","iopub.execute_input":"2023-04-28T16:39:43.468258Z","iopub.status.idle":"2023-04-28T16:39:48.696470Z","shell.execute_reply.started":"2023-04-28T16:39:43.468214Z","shell.execute_reply":"2023-04-28T16:39:48.695011Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 4s 14ms/step - loss: 0.0243 - accuracy: 0.9938\nTest Accuracy:  0.9937999844551086\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Concept of Data Augmentation\n- Deep learning requires to have large dataset. which we often doesnot have.\n- So Data Augmentation rotates, transforms, scales, flips the same image in order to have different images from same image.\n- Reduces the overfitting.","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rotation_range=7, width_shift_range=0.05,height_shift_range=0.07, shear_range=0, zoom_range=0.05)\n\n#Test Image data is not transformed because this transformation will make sure that \n# neural network will work better in the sense that we are able to classify images more precisely.\ntest_generator = ImageDataGenerator()\n\ntrain_generator = train_generator.flow(feature_train, target_train, batch_size=64)\ntest_generator = test_generator.flow(feature_test, target_test, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T17:17:10.594545Z","iopub.execute_input":"2023-04-28T17:17:10.594956Z","iopub.status.idle":"2023-04-28T17:17:10.602529Z","shell.execute_reply.started":"2023-04-28T17:17:10.594921Z","shell.execute_reply":"2023-04-28T17:17:10.601132Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, validation_data=test_generator, validation_steps=10000//64)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T17:17:14.315383Z","iopub.execute_input":"2023-04-28T17:17:14.315819Z","iopub.status.idle":"2023-04-28T17:28:18.101081Z","shell.execute_reply.started":"2023-04-28T17:17:14.315779Z","shell.execute_reply":"2023-04-28T17:28:18.099604Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"name":"stdout","text":"937/937 [==============================] - 96s 101ms/step - loss: 0.0684 - accuracy: 0.9788 - val_loss: 0.0279 - val_accuracy: 0.9910\nEpoch 2/5\n937/937 [==============================] - 93s 99ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 0.0371 - val_accuracy: 0.9891\nEpoch 3/5\n937/937 [==============================] - 94s 100ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0255 - val_accuracy: 0.9922\nEpoch 4/5\n937/937 [==============================] - 94s 100ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0255 - val_accuracy: 0.9924\nEpoch 5/5\n937/937 [==============================] - 94s 100ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0196 - val_accuracy: 0.9936\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x753c82ab1f90>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}